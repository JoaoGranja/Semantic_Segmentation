{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoGranja/Semantic_Segmentation/blob/master/pascal_semantic_segmentation_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fug7eGzTzLbg"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "is_colab = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PycgYA0ppQa"
      },
      "source": [
        "\n",
        "# **Colab Preparation** \n",
        "Before handling the project, we need to install tensorflow/keras and pip packages. I also share my google drive to simplify the connection with my google drive account.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j5egONdppQb",
        "outputId": "15faca81-8ded-442f-92b9-c90b9c755f31"
      },
      "source": [
        "if is_colab:\n",
        "    #Package Installation and share Google Drive\n",
        "    !pip install --upgrade pip\n",
        "    #!pip install --upgrade keras\n",
        "    !pip install keras-resnet\n",
        "    !pip install tensorflow==2.4.0\n",
        "    !pip install tensorflow-gpu==2.4.0\n",
        "    !pip install tensorflow_addons\n",
        "    !pip install keras==2.4\n",
        "\n",
        "    !pip install keras-segmentation\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-21.2.4-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 21.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-21.2.4\n",
            "Collecting keras-resnet\n",
            "  Downloading keras-resnet-0.2.0.tar.gz (9.3 kB)\n",
            "Requirement already satisfied: keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from keras-resnet) (2.6.0)\n",
            "Building wheels for collected packages: keras-resnet\n",
            "  Building wheel for keras-resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-resnet: filename=keras_resnet-0.2.0-py2.py3-none-any.whl size=20486 sha256=4cc0a868c55008c4ac704fa10edebafebe1a8e2c304d16f5876513a6374201e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/ef/06/5d65f696360436c3a423020c4b7fd8c558c09ef264a0e6c575\n",
            "Successfully built keras-resnet\n",
            "Installing collected packages: keras-resnet\n",
            "Successfully installed keras-resnet-0.2.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting tensorflow==2.4.0\n",
            "  Downloading tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7 MB 16 kB/s \n",
            "\u001b[?25hCollecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 27.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.17.3)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 35.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.6.3)\n",
            "Collecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 34.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.19.5)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.6.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.37.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.12.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.6.0)\n",
            "Installing collected packages: grpcio, tensorflow-estimator, h5py, gast, tensorflow\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.41.0\n",
            "    Uninstalling grpcio-1.41.0:\n",
            "      Successfully uninstalled grpcio-1.41.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.6.0\n",
            "    Uninstalling tensorflow-2.6.0:\n",
            "      Successfully uninstalled tensorflow-2.6.0\n",
            "Successfully installed gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting tensorflow-gpu==2.4.0\n",
            "  Downloading tensorflow_gpu-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7 MB 15 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (2.6.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (2.10.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (0.37.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (1.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (1.12.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (1.6.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (1.12)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (1.19.5)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (3.17.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0) (2.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0) (1.35.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.0) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu==2.4.0) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.0) (3.6.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.4.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 32.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.14.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting keras==2.4\n",
            "  Downloading Keras-2.4.0-py2.py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 32.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4) (3.13)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from keras==2.4) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras==2.4) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras==2.4) (2.10.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (2.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (0.12.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (0.3.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (3.7.4.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (0.37.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.1.2)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (2.6.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (3.17.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.32.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.12.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->keras==2.4) (0.2.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (57.4.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->keras==2.4) (3.6.0)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.6.0\n",
            "    Uninstalling keras-2.6.0:\n",
            "      Successfully uninstalled keras-2.6.0\n",
            "Successfully installed keras-2.4.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Collecting keras-segmentation\n",
            "  Downloading keras_segmentation-0.3.0.tar.gz (23 kB)\n",
            "Requirement already satisfied: Keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from keras-segmentation) (2.4.0)\n",
            "Collecting imageio==2.5.0\n",
            "  Downloading imageio-2.5.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 43.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: imgaug==0.2.9 in /usr/local/lib/python3.7/dist-packages (from keras-segmentation) (0.2.9)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from keras-segmentation) (4.1.2.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from keras-segmentation) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.5.0->keras-segmentation) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.5.0->keras-segmentation) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.9->keras-segmentation) (3.2.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.9->keras-segmentation) (1.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.9->keras-segmentation) (0.16.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.9->keras-segmentation) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug==0.2.9->keras-segmentation) (1.4.1)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.0.0->keras-segmentation) (2.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras>=2.0.0->keras-segmentation) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.0.0->keras-segmentation) (2.10.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.9->keras-segmentation) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.9->keras-segmentation) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.2.9->keras-segmentation) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.2.9->keras-segmentation) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.2.9->keras-segmentation) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.2.9->keras-segmentation) (1.3.2)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (1.32.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (2.6.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (2.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (3.7.4.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (0.37.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (1.12)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (0.3.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (3.17.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (0.12.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (1.1.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->Keras>=2.0.0->keras-segmentation) (3.6.0)\n",
            "Building wheels for collected packages: keras-segmentation\n",
            "  Building wheel for keras-segmentation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-segmentation: filename=keras_segmentation-0.3.0-py3-none-any.whl size=29070 sha256=f9116cea0fab5774ac05e0721940dff8d9f9241fdbb65d69ef72fd8706ceae61\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/dc/b3/596a3e2461ba16e935ef31661c26e823f841cfb577cec4c47a\n",
            "Successfully built keras-segmentation\n",
            "Installing collected packages: imageio, keras-segmentation\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.4.1\n",
            "    Uninstalling imageio-2.4.1:\n",
            "      Successfully uninstalled imageio-2.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed imageio-2.5.0 keras-segmentation-0.3.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NToyjnZ4Uc2k"
      },
      "source": [
        " # **Configuration and imports**\n",
        "\n",
        "The first thing I do is to import all modules we need for this project. I also use some configuration parameters to provide more flexibility to the tranining process\n",
        "\n",
        "In this project I will be making use of the Keras library for creating our model and training it. I will also use Matplotlib for visualizing our dataset to gain a better understanding of the images we are going to be handling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk78b8REzLbl"
      },
      "source": [
        "# Generic Imports\n",
        "import time\n",
        "import gc\n",
        "import logging, os\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "import pickle\n",
        "from math import ceil\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "\n",
        "# data processing and visualization library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 \n",
        "\n",
        "# tensorflow and keras for DL model\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "#logging.disable(logging.WARNING)\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "from tensorflow.keras.models import Model, save_model, load_model, Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "#from keras.utils import multi_gpu_model\n",
        "from tensorflow.keras.preprocessing.image import Iterator, load_img, img_to_array, ImageDataGenerator\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "if is_colab:\n",
        "    from google.colab import files\n",
        "    sys.path.append('/content/drive/MyDrive/colab/Semantic_Segmentation')\n",
        "    os.chdir('/content/drive/MyDrive/colab/Semantic_Segmentation')\n",
        "    \n",
        "#------------------------------  Set some configuration parameters -----------------------------------#\n",
        "args = {}\n",
        "args['seed'] = 42\n",
        "args['data_augmentation'] = False\n",
        "args['training'] = True\n",
        "args['fine_tuning'] = True\n",
        "args['evaluation_networks'] = False\n",
        "args['debug'] = False\n",
        "\n",
        "#training arguments\n",
        "args['train_epochs'] = 10\n",
        "args['fine_tune_epochs'] = 10\n",
        "args['validation_split'] = 0.2\n",
        "\n",
        "#model arguments\n",
        "args['compare_networks'] = ['mobileNetV2_Unet', 'mobilenet_fcn_32', 'mobilenet_fcn_8', 'mobilenet_pspnet', \n",
        "                            'mobileNetV2_pspnet', 'mobilenet_segnet', 'mobileNetV2_segnet', 'Deeplabv3']\n",
        "args['network'] = 'Deeplabv3'\n",
        "args['models_dir'] = 'nn_models_checkpoints'\n",
        "\n",
        "#optimizer arguments\n",
        "args['optimizer'] = 'adam'\n",
        "#args['weights'] = 'nn_models_checkpoints/best_{}.h5'.format(args['networks'][0])\n",
        "args['learning_rate'] = 0.001\n",
        "args['decay'] = 0.0001\n",
        "args['loss'] = SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjI2CcCKppQe"
      },
      "source": [
        "## Loading the dataset\n",
        "\n",
        "In this project I will use the CIFAR100 dataset which is comprised of 60000 32x32 color images in 100 classes, with 600 images per class. There are 50000 training images and 10000 test images. More information is available on [CIFAR homepage](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
        "\n",
        "\n",
        "# **Data pre-processing and data augmentation**\n",
        "The dataset output ranges from class 0 to 99. For training a model, it is easier to use a one hot encoding for the class element of each sample, in this way we transform any integer into a 100 element binary vector with a 1 for the index of the class value.\n",
        "\n",
        "In order to improve the model generalization for new unseen images, I will also apply data augmentation process based on random transformations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "7-rrRfjMpwYi",
        "outputId": "4102126a-3589-459a-e65f-785bd7bc0c9f"
      },
      "source": [
        "from dataset.VOC2012 import create_tf_record_voc, parse_record\n",
        "\n",
        "create_tf_record_voc()\n",
        "\n",
        "train_output_path = './dataset/voc12_train.record'\n",
        "val_output_path = './dataset/voc12_val.record'\n",
        "dataset = tf.data.Dataset.from_tensor_slices(train_output_path)\n",
        "dataset = dataset.flat_map(tf.data.TFRecordDataset)\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size=1000)\n",
        "\n",
        "dataset = dataset.map(parse_record)\n",
        "#dataset = dataset.map(\n",
        "#    lambda image, label: preprocess_image(image, label, is_training))\n",
        "dataset = dataset.prefetch(10)\n",
        "\n",
        "# We call repeat after shuffling, rather than before, to prevent separate\n",
        "# epochs from blending together.\n",
        "dataset = dataset.repeat(2)\n",
        "dataset = dataset.batch(10)\n",
        "\n",
        "iterator = dataset.make_one_shot_iterator()\n",
        "images, labels = iterator.get_next()\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "plt.subplot(1, 1, 1)\n",
        "plt.title(\"Image\")\n",
        "plt.imshow(tf.keras.preprocessing.image.array_to_img(images))\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 1, 2)\n",
        "plt.title(\"labels\")\n",
        "plt.imshow(tf.keras.preprocessing.image.array_to_img(labels))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-bde825ace5e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_output_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./dataset/voc12_train.record'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mval_output_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./dataset/voc12_val.record'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_output_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \"\"\"\n\u001b[0;32m--> 691\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   3155\u001b[0m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3156\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3157\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3158\u001b[0m     self._structure = nest.map_structure(\n\u001b[1;32m   3159\u001b[0m         lambda component_spec: component_spec._unbatch(), batched_spec)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mto_batched_tensor_list\u001b[0;34m(element_spec, element)\u001b[0m\n\u001b[1;32m    364\u001b[0m   return _to_tensor_list_helper(\n\u001b[1;32m    365\u001b[0m       lambda state, spec, component: state + spec._to_batched_tensor_list(\n\u001b[0;32m--> 366\u001b[0;31m           component), element_spec, element)\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36m_to_tensor_list_helper\u001b[0;34m(encode_fn, element_spec, element)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m   return functools.reduce(\n\u001b[0;32m--> 340\u001b[0;31m       reduce_fn, zip(nest.flatten(element_spec), nest.flatten(element)), [])\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mreduce_fn\u001b[0;34m(state, value)\u001b[0m\n\u001b[1;32m    335\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mencode_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m   return functools.reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(state, spec, component)\u001b[0m\n\u001b[1;32m    364\u001b[0m   return _to_tensor_list_helper(\n\u001b[1;32m    365\u001b[0m       lambda state, spec, component: state + spec._to_batched_tensor_list(\n\u001b[0;32m--> 366\u001b[0;31m           component), element_spec, element)\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m_to_batched_tensor_list\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0mtensor_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Value %s has insufficient rank for batching.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Value tf.Tensor(b'./dataset/voc12_train.record', shape=(), dtype=string) has insufficient rank for batching."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32RfKAg6ppQf"
      },
      "source": [
        "def normalize(input_image, input_mask):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  input_mask -= 1\n",
        "  return input_image, input_mask\n",
        "\n",
        "def load_image(datapoint, input_shape=128):\n",
        "  input_image = tf.image.resize(datapoint['image'], (input_shape, input_shape))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (input_shape, input_shape))\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask\n",
        "\n",
        "class Augment(tf.keras.layers.Layer):\n",
        "  def __init__(self, seed=42):\n",
        "    super().__init__()\n",
        "    # both use the same seed, so they'll make the same randomn changes.\n",
        "    self.augment_inputs = preprocessing.RandomFlip(mode=\"horizontal\", seed=seed)\n",
        "    self.augment_labels = preprocessing.RandomFlip(mode=\"horizontal\", seed=seed)\n",
        "\n",
        "  def normalize(self, image, label):\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    #label -= 1\n",
        "    return image, label\n",
        "\n",
        "  def call(self, inputs, labels):\n",
        "    inputs = self.augment_inputs(inputs)\n",
        "    labels = self.augment_labels(labels)\n",
        "    inputs, labels = self.normalize(inputs, labels)\n",
        "\n",
        "    return inputs, labels\n",
        "\n",
        "def crop_or_pad_image_and_label(image, label):\n",
        "    \"\"\"Crops and/or pads an image to a target width and height.\n",
        "    Resizes an image to a target width and height by rondomly\n",
        "    cropping the image or padding it evenly with zeros.\n",
        "    Args:\n",
        "      image: 3-D Tensor of shape `[height, width, channels]`.\n",
        "      label: 3-D Tensor of shape `[height, width, 1]`.\n",
        "    Returns:\n",
        "      Cropped and/or padded image.\n",
        "      If `images` was 3-D, a 3-D float Tensor of shape\n",
        "      `[new_height, new_width, channels]`.\n",
        "    \"\"\"\n",
        "    image_shape = 256\n",
        "    label = label - 255  \n",
        "    image_height = tf.shape(image)[0]\n",
        "    image_width = tf.shape(image)[1]\n",
        "\n",
        "    target_height = image_height + tf.maximum(image_shape - image_height, 0)\n",
        "    target_width = image_width + tf.maximum(image_shape - image_width, 0)\n",
        "\n",
        "    # Pad image/label\n",
        "    image = tf.image.pad_to_bounding_box(image, 0, 0, target_height, target_width)\n",
        "    label = tf.image.pad_to_bounding_box(label, 0, 0, target_height, target_width)\n",
        "    \n",
        "    # Crop image/label\n",
        "    image_and_label = tf.concat([image, label], axis=2)\n",
        "    image_and_label_crop = tf.image.random_crop(image_and_label, [image_shape, image_shape, 4])\n",
        "    \n",
        "    image_crop = image_and_label_crop[:, :, :3]\n",
        "    label_crop = image_and_label_crop[:, :, 3:]\n",
        "    label_crop += 255\n",
        "\n",
        "    label_crop = tf.cast(label_crop, tf.int32)\n",
        "\n",
        "    image_crop.set_shape([image_shape, image_shape, 3])\n",
        "    label_crop.set_shape([image_shape, image_shape, 1])\n",
        "\n",
        "    return image_crop, label_crop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QmxIhbxqo2L"
      },
      "source": [
        "from dataset.create_pascal_tf_record import create_pascal_tf_record, parse_record\n",
        "\n",
        "train_output_path = './dataset/voc_train.record'\n",
        "val_output_path = './dataset/voc_val.record'\n",
        "if not os.path.exists(train_output_path):\n",
        "  create_pascal_tf_record()\n",
        "\n",
        "use_pascal_dataset = True\n",
        "if use_pascal_dataset:\n",
        "  #------------------------------  Load dataset using TFRecordDataset -----------------------------------#\n",
        "  train_dataset = tf.data.TFRecordDataset(train_output_path)\n",
        "  train_images = train_dataset.map(parse_record).map(crop_or_pad_image_and_label)\n",
        "\n",
        "  val_dataset = tf.data.TFRecordDataset(val_output_path)\n",
        "  val_images = val_dataset.map(parse_record).map(crop_or_pad_image_and_label)\n",
        "  BATCH_SIZE = 32\n",
        "  BUFFER_SIZE = 100\n",
        "  INPUT_SHAPE = [256,256,3]\n",
        "  OUTPUT_CLASSES = 21\n",
        "  STEPS_PER_EPOCH = 1464 // BATCH_SIZE\n",
        "  VAL_SUBSPLITS = 5\n",
        "  VALIDATION_STEPS = 1449 //BATCH_SIZE//VAL_SUBSPLITS\n",
        "\n",
        "else:\n",
        "  #------------------------------  Load dataset using tf.dataset API -----------------------------------#\n",
        "  dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)\n",
        "  train_images = dataset['train'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "  val_images = dataset['test'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "\n",
        "  BATCH_SIZE = 64\n",
        "  BUFFER_SIZE = 1000\n",
        "  INPUT_SHAPE = [128,128,3]\n",
        "  OUTPUT_CLASSES = 3\n",
        "  STEPS_PER_EPOCH = info.splits['train'].num_examples // BATCH_SIZE\n",
        "  VAL_SUBSPLITS = 5\n",
        "  VALIDATION_STEPS = info.splits['test'].num_examples //BATCH_SIZE//VAL_SUBSPLITS\n",
        "\n",
        "\n",
        "# Create Train and validation Batches\n",
        "train_batches = (\n",
        "    train_images\n",
        "    .cache()                                 # The first time the dataset is iterated over, its elements will be cached either in the specified file or in memory. Subsequent iterations will use the cached data\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE)                       # Combines consecutive elements of this dataset into batches.\n",
        "    .repeat()                                # Repeats this dataset so each original value is seen count times.\n",
        "    .map(Augment())\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)) # This allows later elements to be prepared while the current element is being processed.\n",
        "\n",
        "val_batches = val_images.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v20CtzuppQj"
      },
      "source": [
        "#------------------------------ Plot random images and respective true mask -----------------------------------#\n",
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "for images, masks in train_batches.take(2):\n",
        "  sample_image, sample_mask = images[0], masks[0]\n",
        "  display([sample_image, sample_mask])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ro1q9pD3rlE"
      },
      "source": [
        "\n",
        "def get_uniques(t):\n",
        "    t1d = tf.reshape(t, shape=(-1,))\n",
        "    # or tf.unique, if you don't need counts\n",
        "    uniques, idx, counts = tf.unique_with_counts(t1d) \n",
        "    return uniques, idx, counts \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLijVktappQk"
      },
      "source": [
        "Analyzing the images it is clear that the images resolution is small, actually 32x32 has few pixels and therefore can be a challenge for a model to classify correctly the object. Furthermore all image has the same size so it is not required to resize the input images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9i_voo8zLbs"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QCnufRUl-Z5"
      },
      "source": [
        "# **Optimizer**\n",
        "\n",
        "Before training it is necessary to choose an optimizer which will be responsible to adjust model parameters in order to reduce the loss funcion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INAQZOJSphOA"
      },
      "source": [
        "#------------------------------ Define an optimizer -----------------------------------#\n",
        "if 'optimizer' in args:\n",
        "    if args['optimizer'] == 'rmsprop':\n",
        "        optimizer = RMSprop(learning_rate=args['learning_rate'], decay=float(args['decay']))\n",
        "    elif args['optimizer'] == 'adam':\n",
        "        optimizer = Adam(learning_rate=args['learning_rate'], decay=float(args['decay']))\n",
        "    elif args['optimizer'] == 'amsgrad':\n",
        "        optimizer = Adam(learning_rate=args['learning_rate'], decay=float(args['decay']), amsgrad=True)\n",
        "    elif args['optimizer'] == 'sgd':\n",
        "        optimizer = SGD(learning_rate=args['learning_rate'], momentum=0.9, nesterov=True, decay=float(args['decay']))\n",
        "else:\n",
        "    optimizer = RMSprop(learning_rate=args['learning_rate'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWLJo5_bppQs"
      },
      "source": [
        "# **Model**\n",
        "\n",
        "In this project, I will use simple and light CNN models. One model follows the LeNet architecture which is built from scratch and two models are the pre-trained VGG16 and VGG19 models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd5VM-R-Su0_"
      },
      "source": [
        "from models.model_factory import make_model\n",
        "\n",
        "if args['training']:\n",
        "  #------------------------------ Make the model -----------------------------------#\n",
        "  model = make_model(args['network'], INPUT_SHAPE, OUTPUT_CLASSES)\n",
        "\n",
        "  if 'weights' not in args:\n",
        "      print('No weights passed, training from scratch')\n",
        "  else:\n",
        "      print('Loading weights from {}'.format(args['weights']))\n",
        "      model.load_weights(args['weights'], by_name=True)\n",
        "\n",
        "  #------------------------------ Compile the model -----------------------------------#\n",
        "  model.compile(loss=args['loss'], optimizer=optimizer, metrics=['accuracy']) \n",
        "\n",
        "if args['debug']:\n",
        "  model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67xkObzz4V2Y"
      },
      "source": [
        "if args['debug']:\n",
        "  plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSADHpegzLb-"
      },
      "source": [
        "# **Training**\n",
        "\n",
        "This step called trainig comprises on fitting the model parameters to classify correcty the images. For that, the optimizer uses a loss function to quantify the discrepance between true and predicted labels Based on that it adjusts the model parameters to decrease the loss. Model checkpoints, EarlyStopping and Learning Rate reduce are used as callbacks to improce training efficiency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnorvMQ-4-QH"
      },
      "source": [
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  return pred_mask[0]\n",
        "\n",
        "def show_predictions(dataset=None, num=1):\n",
        "  if dataset:\n",
        "    for image, mask in dataset.take(num):\n",
        "      pred_mask = model.predict(image)\n",
        "      display([image[0], mask[0], create_mask(pred_mask)])\n",
        "  else:\n",
        "    display([sample_image, sample_mask,\n",
        "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n",
        "\n",
        "\n",
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    clear_output(wait=True)\n",
        "    show_predictions()\n",
        "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
        "\n",
        "\n",
        "def add_sample_weights(image, label):\n",
        "  # The weights for each class, with the constraint that:\n",
        "  #     sum(class_weights) == 1.0\n",
        "  class_weights = tf.constant([2.0, 2.0, 1.0])\n",
        "  class_weights = class_weights/tf.reduce_sum(class_weights)\n",
        "\n",
        "  # Create an image of `sample_weights` by using the label at each pixel as an \n",
        "  # index into the `class weights` .\n",
        "  sample_weights = tf.gather(class_weights, indices=tf.cast(label, tf.int32))\n",
        "\n",
        "  return image, label, sample_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSWGGh32Svnu"
      },
      "source": [
        "gc.collect\n",
        "#------------------------------ Model check points -----------------------------------#\n",
        "best_model_file = '{}/best_{}.h5'.format(args['models_dir'], model.name)\n",
        "last_model_file = '{}/last_{}.h5'.format(args['models_dir'], model.name)\n",
        "model_file = '{}/model_{}.h5'.format(args['models_dir'], model.name)\n",
        "\n",
        "#------------------------------ Callbacks -----------------------------------#\n",
        "\n",
        "#ModelCheckpoint(filepath=last_model_file, monitor='val_loss', verbose=1, mode='min',\n",
        "#            save_freq='epoch', save_best_only=False, save_weights_only=False)\n",
        "\n",
        "# Callback to reduce the learning rate once the plateau has been reached:\n",
        "reduceLr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0.05,\n",
        "    factor=1/3,\n",
        "    patience=3,\n",
        "    mode='auto',\n",
        "    verbose=1,\n",
        "    cooldown=0,\n",
        "    min_lr=1e-8\n",
        "),\n",
        "# Callback to stop the training once no more improvements are recorded:\n",
        "earlyStopping = EarlyStopping(\n",
        "    min_delta=0.001,\n",
        "    verbose=1,\n",
        "    patience=10,\n",
        "    mode='auto',\n",
        "    restore_best_weights=True\n",
        "),\n",
        "# Callback to log the graph, losses and metrics into TensorBoard:\n",
        "tensorBoard = TensorBoard(log_dir=\"logs/{}\".format(model.name)\n",
        "),\n",
        "# Callback to save the best model specifying the epoch and val-loss in the filename:\n",
        "model_checkPoint = ModelCheckpoint(filepath=best_model_file, \n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    mode='min',\n",
        "    save_freq='epoch',\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False)\n",
        "\n",
        "\n",
        "callbacks = [reduceLr, earlyStopping, model_checkPoint, DisplayCallback()] #tensorBoard, \n",
        "\n",
        "if args['training']:\n",
        "    print(\"Training model {}\".format(model.name))\n",
        "    #------------------------------ Model Fit -----------------------------------#\n",
        "    history = model.fit(\n",
        "                        train_batches,\n",
        "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                        epochs=args['train_epochs'],\n",
        "                        validation_steps=VALIDATION_STEPS,\n",
        "                        validation_data=val_batches,\n",
        "                        callbacks=callbacks)\n",
        "\n",
        "    #------------------------------ Save the last model weights -----------------------------------#\n",
        "    model.save(model_file)\n",
        "    print(\"Saved model to disk\") \n",
        "else:\n",
        "  model = load_model(model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szQZCm1WzprW"
      },
      "source": [
        "# **Fine tuning**\n",
        "\n",
        "In the feature extraction experiment, you were only training a few layers on top of an base model. The weights of the pre-trained network were not updated during training. \n",
        "\n",
        "One way to increase performance even further is to train (or \"fine-tune\") the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic feature maps to features associated specifically with the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRobxT6d0DeF"
      },
      "source": [
        "if args['fine_tuning']:\n",
        "  #base_model = model.get_layer('encoder')\n",
        "  #base_model.trainable = True\n",
        "\n",
        "  # Let's take a look to see how many layers are in the base model\n",
        "  #print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "  # Fine-tune from this layer onwards\n",
        "  #fine_tune_at = 100\n",
        "\n",
        "  # Freeze all the layers before the `fine_tune_at` layer\n",
        "  #for layer in base_model.layers[:fine_tune_at]:\n",
        "   # layer.trainable =  False\n",
        "\n",
        "  #------------------------------ Compile the model -----------------------------------#\n",
        "  model.compile(loss=args['loss'], optimizer=RMSprop(learning_rate=args['learning_rate']/10), metrics=['accuracy']) \n",
        "  model.summary()\n",
        "\n",
        "  #------------------------------ Model Fit -----------------------------------#\n",
        "  total_epochs =  args['train_epochs'] + args['fine_tune_epochs']\n",
        "  fine_tune_history = model.fit(\n",
        "                        train_batches.map(add_sample_weights),\n",
        "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                        epochs=total_epochs,\n",
        "                        initial_epoch = args['train_epochs'],\n",
        "                        validation_steps=VALIDATION_STEPS,\n",
        "                        validation_data=test_batches,\n",
        "                        callbacks=callbacks)\n",
        "\n",
        "  #------------------------------ Save the last model weights -----------------------------------#\n",
        "  model.save(model_file)\n",
        "  print(\"Saved model to disk\")    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI4rNBwYgXwv"
      },
      "source": [
        "# **Visualise Model Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tUF9-UtppQx"
      },
      "source": [
        "#------------------------------ Plot diagnostic learning curves -----------------------------------#\n",
        "def summarize_diagnostics(history, model_name, fine_tune_history={}):\n",
        "    # plot loss\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    if args['fine_tuning']:\n",
        "      acc += fine_tune_history.history['accuracy']\n",
        "      val_acc += fine_tune_history.history['val_accuracy']\n",
        "\n",
        "      loss += fine_tune_history.history['loss']\n",
        "      val_loss += fine_tune_history.history['val_loss']  \n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(2,1,1)\n",
        "    plt.plot(acc, label='Training Accuracy')\n",
        "    plt.plot(val_acc, label='Validation Accuracy')\n",
        "    plt.ylim([0.1, 1])\n",
        "    if args['fine_tuning']:\n",
        "      plt.plot([args['train_epochs'],args['train_epochs']],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(2,1,2)\n",
        "    plt.plot(loss, label='Training Loss')\n",
        "    plt.plot(val_loss, label='Validation Loss')\n",
        "    #plt.ylim([0, 10])\n",
        "    if args['fine_tuning']:\n",
        "      plt.plot([args['train_epochs'],args['train_epochs']],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    \n",
        "    # save plot to file\n",
        "    plt.savefig(\"results_\" + model_name  + '_plot.png')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "if args['training']:  \n",
        "    if args['fine_tuning']:\n",
        "      summarize_diagnostics(history, args['network'], fine_tune_history)\n",
        "    else:\n",
        "      summarize_diagnostics(history, args['network'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhLAxcKs7QJL"
      },
      "source": [
        "show_predictions(test_batches, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg9NFaPNzLcH"
      },
      "source": [
        "# **Evaluation**\n",
        "\n",
        "Evaluate the model over the test dataset. We will use the last model weights and predict the class for some test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HGuxPkippQy"
      },
      "source": [
        "gc.collect\n",
        "if args['evaluation_networks']:\n",
        "\n",
        "  def show_image_prediction(loaded_model, n_images):\n",
        "    #Try out the model on an image from the test data:\n",
        "    #plt.figure(figsize=(30, 30))\n",
        "    fig, axs = plt.subplots(1, n_images, figsize=(15, 15))\n",
        "    fig.tight_layout(pad=1.0)\n",
        "\n",
        "    # View the images\n",
        "    for i in range(n_images):\n",
        "        index = random.randint(0, len(x_test))\n",
        "        image = x_test[index].squeeze()\n",
        "        true_index = [i for i in range(nr_classes) if y_test[index][i] == 1 ][0]\n",
        "\n",
        "        prediction_scores = loaded_model.predict(np.expand_dims(image, axis=0))\n",
        "        predicted_index = np.argmax(prediction_scores)\n",
        "\n",
        "        #image = np.add(image*128,128).astype(int)\n",
        "        axs[i].imshow(image)\n",
        "        axs[i].set_title(\"True Label = {0}, \\n Predicted label = {1}\".format(true_index, predicted_index))\n",
        "        axs[i].get_xaxis().set_visible(False)\n",
        "        axs[i].get_yaxis().set_visible(False)\n",
        "    \n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "  #------------------------------ Predict on some test images -----------------------------------#\n",
        "  i=1\n",
        "\n",
        "  for network in args['compare_networks']:\n",
        "      print(\"----------------------- model {} -----------------------\".format(network))\n",
        "\n",
        "\n",
        "      #plt.subplot(1, len(args['networks']), i)\n",
        "      #Load last model parameters\n",
        "      last_model_file = '{}/last_{}.h5'.format(args['models_dir'], network)\n",
        "      best_model_file = '{}/best_{}.h5'.format(args['models_dir'], network)\n",
        "      model_file = '{}/model_{}.h5'.format(args['models_dir'], network)\n",
        "\n",
        "      #Load the model\n",
        "      loaded_model = load_model(model_file)\n",
        "      print(\"Loaded model {} from disk\".format(model_file))\n",
        "      loaded_model.compile(loss=args['loss'], optimizer=optimizer, metrics=['accuracy']) \n",
        "\n",
        "      #Try out the model on an image from the test data:\n",
        "      show_image_prediction(loaded_model,8)\n",
        "\n",
        "      #------------------------------ Evaluate model on testing dataset -----------------------------------#\n",
        "      #_, acc = loaded_model.evaluate(x_train, y_train, verbose=0)\n",
        "      #print(\"Training accuracy of model {0} = {1}\".format(loaded_model.name, acc))\n",
        "      _, acc = loaded_model.evaluate(x_test, y_test, verbose=0)\n",
        "      print(\"Testing accuracy of model {0} = {1}\".format(loaded_model.name, acc)) \n",
        "\n",
        "      #------------------------------ Plot all model results -----------------------------------#\n",
        "      # save plot to file\n",
        "      filename = \"accuracy_\" + network + '_plot.png'\n",
        "      im = cv2.imread(filename)\n",
        "      plt.imshow(im)\n",
        "      plt.title(\"Accuray Results of model {}\".format(network))\n",
        "      i = i + 1\n",
        "\n",
        "      plt.show()\n",
        "  plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfrD3I1TYU8L"
      },
      "source": [
        "Comparing the results obtained from the three models *LeNet*, *VGG16* and *VGG19*, it is possible to conclude the model with the best result is *VGG16* followed by *VGG19*. Indeed *VGG16* has the highest accuracy evaluated on testing dataset. Due to reduced capacity, *LeNet* starts overfiting earlier, actually the fine-tuning process didn't improve model results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6ajPGnahFrv"
      },
      "source": [
        "**Conclusion**\n",
        "\n",
        "In this project I built from scratch a simple LeNet model and used 2 pre-trained models, VGG16 and VGG19. I train all models and evaluate the results against the CIFAR10 testing dataset. Taking into account the accuracy, the best model for this dataset was VGG16. \n",
        "\n",
        "So in this project, I applied several workflow steps to train a deep learning model on the image classification problem. In sume the steps were: pre-processing the input data, apply data-augmentation, build a CNN model, use pre-trained models, train a model, fine-tuning the model and evaluate the model. \n",
        "\n",
        "I used transfer learning technique on VGG16 and VGG19 models which is usefull when our dataset is not so large like in this case. The models accuracy on testing dataset is around 81/83% which are good results. \n",
        "\n",
        "For future work, I could apply better data augmentation in order to avoid overfitting as well as regularization techniques like L1 or L2. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q9aWqIvhGMm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}